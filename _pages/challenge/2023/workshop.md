---
title: "The 5th Large-scale Video Object Segmentation Challenge"
permalink: /challenge/2023/
excerpt: "Workshop in conjunction with ICCV 2023, Paris, France"
classes: wide
header:
  overlay_filter: rgba(232, 74, 39, 0.8)
  overlay_image: /assets/banner.jpg
sidebar:
  nav: "challenge"
---

## Introduction
The 5th LSVOS challenge will be held in conjunction with [ICCV 2023](https://iccv2023.thecvf.com/) in Paris, France. In this edition of the workshop and challenge, we are combining the classic [YouTube-VOS](https://youtube-vos.org/) benchmark with the newly introduced [VOST](https://www.vostdataset.org/) dataset. VOST focuses on complex object transformations, such as egg cracking or molding of clay, which break the assumptions behind existing methods and require rethinking the basic design principles behind them. The combined challenge will be held in conjunction with video instance segmentation and referring video object segmentation YouTube-VOS competitions. In addition, we will hold a series of talks by the leading experts in video understating. The workshop will culminate in a round table discussion, in which speakers will debate the future of video object representations. 


## Dates
* **May 26th**: Codalab websites open for registration. Training and validation data are released.  
* **Aug 1st - 10th**: Release test data and open the submission of the test results.
* **Aug 17th**: The final competition results will be announced and top teams will be invited to give oral/poster presentations at our ICCV 2023 workshop.
* **Oct 2nd**: The workshop will take place in conjunction with ICCV at room S02, Paris Convention Center. 

## Invited Speakers

<figure style="width: 150px" class="align-left">
  <img src="{{ site.baseurl }}/assets/people/KristenGrauman.jpg" alt="Kristen Grauman">
</figure>

### Kristen Grauman
Professor in the Department of Computer Science at the University of Texas at Austin  
[[Homepage]](https://www.cs.utexas.edu/users/grauman/)

<br />
<br />
<br />
<br />
<br />
<br />

<figure style="width: 150px" class="align-left">
  <img src="{{ site.baseurl }}/assets/people/CarlVondrick.jpg" alt="Carl Vondrick">
</figure>

### Carl Vondrick
Associate Professor of Computer Science at Columbia University  
[[Homepage]](http://www.cs.columbia.edu/~vondrick/)

<br />
<br />
<br />
<br />
<br />
<br />

<figure style="width: 150px" class="align-left">
  <img src="{{ site.baseurl }}/assets/people/CordeliaSchmid.gif" alt="Cordelia Schmid">
</figure>

### Cordelia Schmid
INRIA Research Director, Head of the THOTH project-team  
[[Homepage]](https://thoth.inrialpes.fr/people/schmid/)

<br />
<br />
<br />
<br />
<br />
<br />

<figure style="width: 150px" class="align-left">
  <img src="{{ site.baseurl }}/assets/people/AdamHarley.jpg" alt="Adam Harley">
</figure>

### Adam Harley
Postdoc in Prof. Leonidas Guibas' lab, at Stanford University  
[[Homepage]](https://adamharley.com/)

<br />
<br />
<br />
<br />
<br />
<br />

<figure style="width: 150px" class="align-left">
  <img src="{{ site.baseurl }}/assets/people/LauraLealTaixe.jpg" alt="Laura Leal-Taixe">
</figure>

### Laura Leal-Taixe
Senior Research Manager at NVIDIA, Adjunct Professor at the Technical University of Munich (TUM)  
[[Homepage]](https://dvl.in.tum.de/team/lealtaixe/)

<br />
<br />
<br />
<br />
<br />
<br />

<figure style="width: 150px" class="align-left">
  <img src="{{ site.baseurl }}/assets/people/ThomasKipf.jpg" alt="Thomas Kipf">
</figure>

### Thomas Kipf
Senior Research Scientist at Google Brain  
[[Homepage]](https://tkipf.github.io/)


<br />
<br />
<br />
<br />
<br />
<br />
<figure style="width: 150px" class="align-left">
  <img src="{{ site.baseurl }}/assets/people/BenjaminPeters.jpg" alt="Benjamin Peters">
</figure>

### Benjamin Peters
Marie Curie Fellow at the University of Glasgow
[[Homepage]](http://www.imp-frankfurt.de/peters.html#about)
<br />
<br />
<br />
<br />
<br />
<br />

<br />
<br />

## Workshop schedule
Oct 2, 2023, 8:30 - 17:20 GMT+2 @room S02

[Zoom link](https://us06web.zoom.us/j/84100538001?pwd=EUDw0ForkPax82JTsUHDzQ9e1kNc9w.1) (code: 720009)

| Time (GMT+2)    | Event     | Speaker    |
|:-------------|:----------|:-----------|
| 8:30 | **Opening remarks** | Host |
| 8:40 | **Invited Talk #1**: VIS-Ã -MOT-: A face-to-face of video tracking benchmarks | Tim Meinhardt (NVDIA) |
| 9:10 | **VOS Track introduction**  | Host |
| 9:20 | **Video Object Segmentation under Transformations problem introduction**  | Host |
| 9:30 | **VOS winning teams talks**  | Challenge participants |
| 10:00 | **Invited Talk #2**: All the Ways to Track Occluded Objects | Carl Vondrick (Columbia University) |
| 10:30 | **Coffee Break** |  |
| 10:50 | **Invited Talk #3**:Dynamic object vision in humans and machines: Bridging human cognitive science and computer vision  | Benjamin Peters (University of Glasgow and Columbia University) |
| 11:20 | **Video Instance Segmentation track introduction** | Host |
| 11:30 | **VIS winning teams talks**  | Challenge participants |
| 12:00 | **Invited Talk #4**: TBD |  Kristen Grauman (UT Austin and Meta) |
| 12:30 | **Lunch Break** | |
| 13:30 | **Invited talk #5**: Large-Scale Fine-Grained Tracking | Adam Harley (Stanford University) |
| 14:00 | **Referring VOS track introduction** | Host |
| 14:10 | **RVOS winning teams talks** | Challenge participants |
| 14:40 | **Invited Talk #6**: Dense video object captioning | Cordelia Schmid (Inria and Google Research) | 
| 15:10 | **Coffee Break** | | 
| 15:30 | **Invited talk #7**: TBD | Thomas Kipf (Google Deepmind) | 
| 16:00 | **Roundtable discussion**  | |
| 17:00 | **Closing marks** | Host |
| 17:20 | **Workshop Ends** | |


## Organizers

:-:|:-:|:-:|:-:|:-:
<img src="{{ site.baseurl }}/assets/people/NingXu.jpg" width="500" alt="Ning Xu" />|<img src="{{ site.baseurl }}/assets/people/PavelTokmakov.jpg" width="500" alt="Pavel Tokmakov" />|<img src="{{ site.baseurl }}/assets/people/LinjieYang.jpg" width="500" alt="Linjie Yang" />|<img src="{{ site.baseurl }}/assets/people/YuchenFan.jpg" width="500" alt="Yuchen Fan" />|<img src="{{ site.baseurl }}/assets/people/JieLi.jpg" width="500" alt="Jie Li" />
**[Ning Xu](https://sites.google.com/view/ningxu/)**<br />Apple Inc. | **[Pavel Tokmakov](https://pvtokmakov.github.io/home/)**<br />Toyota Research Institute | **[Linjie Yang](https://sites.google.com/site/linjieyang89/)**<br />ByteDance Inc. | **[Yuchen Fan](https://ychfan.github.io/)**<br />Meta Reality Labs | **Jie Li**<br />NVIDIA
<img src="{{ site.baseurl }}/assets/people/Achal.jpg" width="520" alt="Achal Dave" /> | <img src="{{ site.baseurl }}/assets/people/AdrienGaidon.jpg" width="500" alt="Adrien Gaidon" />|<img src="{{ site.baseurl }}/assets/people/JoonYoungLee.jpg" width="500" alt="Joon-Young Lee" />|<img src="{{ site.baseurl }}/assets/people/SeongukSeo.jpg" width="500" alt="Seonguk Seo" />
**[Achal Dave](https://www.achaldave.com/)**<br />Toyota Research Institute | **[Adrien Gaidon](https://adriengaidon.com/)**<br />Toyota Research Institute | **[Joon-Young Lee](https://joonyoung-cv.github.io/)**<br />Adobe Research | **[Seonguk Seo](https://seoseong.uk/)**<br />SNU, Korea

